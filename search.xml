<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Jarvis Alpha</title>
    <url>/2024/08/15/Jarvis-Alpha/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>語音助理最廣為人知的應該是 Siri 以及 Alexa 了，而在電影 Iron man 中，有個 AI 叫做 J.A.R.V.I.S，專門幫助 Tony Stark 完成各種任務。雖然電影後面他發生了一些事，導致被另一個叫 Friday 的 AI 取代，有興趣的可以去觀看原作。其實我一直以來都很想有個語音AI，協助我處理各種事。兩年前我曾嘗試用 Open AI 的 ChatGPT API，由於 Open AI 訓練完 GPT3 模型之後，開始從開源逐漸走向收費，而 ChatGPT 的 API 免費版有用量限制，最後我專案還沒完成，卻已經用光所有的額度了。曾經有想過要自己訓練模型，但看著桌上的電腦，又默默地放下這個念頭，現階段訓練 AI 需要的硬體設備對我來說是遙不可及。但經過了兩年的時間，越來越多公司投入 AI 領域而且也「開源」了許多模型，也就是說不需要付費便能使用的 AI 模型。Jarvis 版本的命名採拉丁字母的順序，依照 Alpha, Beta, Gama…. 命名下去。這篇是 Jarvis Alpha 版本，我之後會陸續發部改良後的版本，雖然都叫 Jarvis 但其實使用的工具幾乎不一樣。Jarvis Alpha 版是以 Pyhon 進行編寫，我會將專案放在 <a href="https://github.com/Bakersite/Jarvis-Alpha.git">Jarvis-Alpha</a> 。</p>
<h1 id="Huggingface-的工具"><a href="#Huggingface-的工具" class="headerlink" title="Huggingface 的工具"></a>Huggingface 的工具</h1><h2 id="HuggingChat"><a href="#HuggingChat" class="headerlink" title="HuggingChat"></a>HuggingChat</h2><p>這邊要介紹 <a href="https://huggingface.co/">Huggingface</a>，這是一個存放很多開源模型的平台，他除了有模型以外，也提供深度學習框架，有興趣的可以去探索一下，這邊會著墨在他底下一個叫 <a href="https://huggingface.co/chat/">HuggingChat</a> 的生成式 AI 服務。由於在 Alpha 版中尚未用到使用 Huggingface 上的模型，因此有關模型的取用會留到 Beta 版在說明。</p>
<p>HuggingChat 類似於大家熟悉的 ChatGPT ，比較不一樣在 HuggingChat 有許多種模型可以選擇。HuggingChat 也可以自定義 AI 的目的，像是以資深的軟體工程師來修正程式碼，可以在建立對話時便設定好，不需要每次都發送指定 AI 角色的 prompt。</p>
<p>實作時會需要 Huggingface 的帳號，若要實作，可以先申請。</p>
<p>P.S. 此文章發布時有一款模型 Llama3.1，由 Meta 訓練的開源模型，「據說」可以匹敵 Open AI 的 gpt-4o mini，各位可以玩玩看。</p>
<h2 id="Hugging-Chat-API"><a href="#Hugging-Chat-API" class="headerlink" title="Hugging Chat API"></a>Hugging Chat API</h2><p><a href="https://github.com/Soulter/hugging-chat-api">Hugging-Chat-API</a>它是一個大佬寫的，並不是 Huggingface 官方的 API，在 Alpha 版中我會利用它來連接 Hugging Chat 當作 Jarvis 的大腦，若有要實作的請先下載，建議參閱網站的說明文件，下面的安裝參考會比較簡潔。說明文件有詳細的指引，大家也可以試試用他的說明指引，自己做一個語音 AI。</p>
<h1 id="實作"><a href="#實作" class="headerlink" title="實作"></a>實作</h1><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><pre class="mermaid">flowchart LR
A(Speech to Text) 
B(Hugging Chat API) 
C[(Hugging Chat server)]
D(Text to Speech)
A --> B --> C --> D --> A</pre>

<p>語音 AI 主要可以拆成三個步驟。</p>
<ol>
<li>語音辨識成文字 </li>
<li>由生成式 AI 當作大腦進行理解 </li>
<li>將生成的文字合成語音並播放</li>
</ol>
<h2 id="語音辨識"><a href="#語音辨識" class="headerlink" title="語音辨識"></a>語音辨識</h2><p>在這裡我們使用 Python 一個叫 <a href="https://pypi.org/project/SpeechRecognition/">Speech Recognition</a> 的工具，利用這工具將語音轉換成文字。以下是簡易的安裝方法，完整說明可以參閱官方文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install SpeechRecognition</span><br></pre></td></tr></table></figure>

<p>接下來只需要在 python 中導入模組即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br></pre></td></tr></table></figure>

<p>先初始化麥克風（建議放在程式碼開頭）接著我們將音訊輸入源調成麥克風，這裡會用 Google 的 Speech to Text 服務，將語音轉成文字，並存入 message 這個變數裡面。這裡會用 try, except 來處理無法辨識語音及連線到 Google 伺服器的錯誤（這邊我沒有將 Google 伺服器回彈的錯誤碼輸出，可以自己更改程式，或是直接在終端機查看）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># initialize the recognizer</span></span><br><span class="line">r = sr.Recognizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># use the microphone as the source for input</span></span><br><span class="line"><span class="keyword">with</span> sr.Microphone() <span class="keyword">as</span> source:                             <span class="comment"># 設定麥克風為音訊輸入源</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;Adjusting for ambient noise, please wait...&quot;</span>)</span><br><span class="line">	r.adjust_for_ambient_noise(source)                      <span class="comment"># 處理背景雜音</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;Say something!&quot;</span>)</span><br><span class="line">	audio = r.listen(source)                                <span class="comment"># 開始收音</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		message = r.recognize_google(audio)                 <span class="comment"># 將語音轉成文字</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;ME: &quot;</span>, r.recognize_google(audio))</span><br><span class="line">	<span class="keyword">except</span> sr.UnknownValueError:                            <span class="comment"># 語音無法辨識</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Google Web Speech could not understand the audio&quot;</span>)</span><br><span class="line">	<span class="keyword">except</span> sr.Request <span class="keyword">as</span> e:                                 <span class="comment"># google伺服器錯誤訊息</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Could not request results form Google Web service&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Brain"><a href="#Brain" class="headerlink" title="Brain"></a>Brain</h2><p>確認已安裝 Hugging Chat API。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip instal hugchat</span><br></pre></td></tr></table></figure>

<p>接著將 Hugging Chat 導入到程式碼。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> hugchat <span class="keyword">import</span> hugchat</span><br><span class="line"><span class="keyword">from</span> hugchat.login <span class="keyword">import</span> Login</span><br></pre></td></tr></table></figure>

<p>導入完後，確認已申請 Huggingface 的帳號，並將 email, passwd 分別輸入申請時的電子郵件帳號及 Huggingface 的密碼，這是用來在 python 程式中登入 Huggingface 帳號來使用 Hugging Chat的功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># login</span></span><br><span class="line">email = <span class="string">&quot;&quot;</span>                                                  <span class="comment"># 請輸入自己的email</span></span><br><span class="line">passwd = <span class="string">&quot;&quot;</span>                                                 <span class="comment"># 請輸入自己的密碼</span></span><br><span class="line">sign = Login(email, passwd)</span><br><span class="line">cookies = sign.login()</span><br></pre></td></tr></table></figure>

<p>登入完後就可以啟動它了，這邊所使用 jarvis 變數可以改成任何名字。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># activate</span></span><br><span class="line">jarvis = hugchat.ChatBot(cookies=cookies.get_dict())</span><br></pre></td></tr></table></figure>

<p>這邊建議將 login 和 activate 這兩個片段放在程式碼前端，完整程式碼我會放在最尾端。<br>接著我們在語音辨識的程式碼後面將辨識好的文字送給 Hugging Chat 生成回答。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = jarvis.chat(message)</span><br></pre></td></tr></table></figure>

<h2 id="語音合成"><a href="#語音合成" class="headerlink" title="語音合成"></a>語音合成</h2><p>終於來到語音合成。這裡使用的語音合成模型會是 Google 的 gTTS，語音合成模型很多，也可以使用pytts 或是 OpenAI 的whisperAPI（這要付費，有一個開源模型也是whisper，是 OpenAI 訓練的，但他只有與語音轉文字而已，在 Gama 版我會介紹並使用）。除了 gTTS 我還會再使用 pydub 方便合成處理及播放音訊。<br>安裝 <a href="https://pypi.org/project/gTTS/">gTTS</a> 及 <a href="https://pypi.org/project/pydub/">pydub</a>可以參閱說明文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install gTTS pydub</span><br></pre></td></tr></table></figure>

<p>接著只要將 gTTS 導入 python 程式就可以了。這裡我們要使用 pydub 裡的 AudioSegment 及 play 而已，以此只導入這兩個函式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gtts <span class="keyword">import</span> gTTS</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pydub <span class="keyword">import</span> AudioSegment</span><br><span class="line"><span class="keyword">from</span> pydub.playback <span class="keyword">import</span> play</span><br></pre></td></tr></table></figure>

<p>導入完工具後，接下來進行語音合成。設定合成的語言是英文，再把檔案存成 mp3 格式，但因為在之後用 pygame 編寫 GUI (使用者介面）時，只支援 16 位的 PCM wav 檔，因此要做轉檔的動作，有關 GUI 介面我會再找時間發一篇文章。 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">speak</span>(<span class="params">text</span>):</span><br><span class="line">	tts = gTTS(text=text, lang=<span class="string">&#x27;en&#x27;</span>) <span class="comment"># 合成語言設定</span></span><br><span class="line">	tts.save(<span class="string">&quot;response.mp3&quot;</span>)         <span class="comment"># 音檔為 mp3 </span></span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 轉換為 16 位 PCM 格式的 WAV 文件</span></span><br><span class="line">	audio = AudioSegment.from_mp3(<span class="string">&quot;response.mp3&quot;</span>)</span><br><span class="line">	audio = audio.set_frame_rate(<span class="number">44100</span>).set_channels(<span class="number">2</span>).set_sample_width(<span class="number">2</span>)</span><br><span class="line">	audio.export(<span class="string">&quot;response.wav&quot;</span>, <span class="built_in">format</span>=<span class="string">&#x27;wav&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>編寫完函式，只要將 Hugging Chat 產生的回答放入 speak 函式中就可以生成音檔了。最後在用play 播放音檔，我會習慣在語音播放完後輸出文字，確認講的內容，這行可以自行刪減。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">speak(<span class="built_in">str</span>(response))           <span class="comment"># 強制轉型 string 格式怕 response 產生的文字格式不是字串</span></span><br><span class="line">play(AudioSegment.from_wav(<span class="string">&quot;response.wav&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<h1 id="完整的程式碼"><a href="#完整的程式碼" class="headerlink" title="完整的程式碼"></a>完整的程式碼</h1><p>我在這裡加上了迴圈及停止方法（按下 Ctrl + C）可以終止程式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> speech_recognition <span class="keyword">as</span> sr</span><br><span class="line"><span class="keyword">from</span> hugchat <span class="keyword">import</span> hugchat</span><br><span class="line"><span class="keyword">from</span> hugchat.login <span class="keyword">import</span> Login</span><br><span class="line"><span class="keyword">from</span> gtts <span class="keyword">import</span> gTTS</span><br><span class="line"><span class="keyword">from</span> pydub <span class="keyword">import</span> AudioSegment</span><br><span class="line"></span><br><span class="line"><span class="comment"># speaking</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">speak</span>(<span class="params">text</span>):</span><br><span class="line">	tts = gTTS(text=text, lang=<span class="string">&#x27;en&#x27;</span>)</span><br><span class="line">	tts.save(<span class="string">&quot;response.mp3&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 轉換為 16 位 PCM 格式的 WAV 文件</span></span><br><span class="line">	audio = AudioSegment.from_mp3(<span class="string">&quot;response.mp3&quot;</span>)</span><br><span class="line">	audio = audio.set_frame_rate(<span class="number">44100</span>).set_channels(<span class="number">2</span>).set_sample_width(<span class="number">2</span>)</span><br><span class="line">	audio.export(<span class="string">&quot;response.wav&quot;</span>, <span class="built_in">format</span>=<span class="string">&#x27;wav&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the recognizer</span></span><br><span class="line">r = sr.Recognizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># log in</span></span><br><span class="line">email = <span class="string">&quot;&quot;</span></span><br><span class="line">passwd = <span class="string">&quot;&quot;</span></span><br><span class="line">sign = Login(email, passwd)</span><br><span class="line">cookies = sign.login()</span><br><span class="line"></span><br><span class="line"><span class="comment"># activate bot</span></span><br><span class="line">jarvis = hugchat.ChatBot(cookies=cookies.get_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate response</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		<span class="comment"># use the microphone as the source for input</span></span><br><span class="line">		<span class="keyword">with</span> sr.Microphone() <span class="keyword">as</span> source:</span><br><span class="line">			<span class="built_in">print</span>(<span class="string">&quot;Adjusting for ambient noise, please wait...&quot;</span>)</span><br><span class="line">			r.adjust_for_ambient_noise(source)</span><br><span class="line">			<span class="built_in">print</span>(<span class="string">&quot;Say something!&quot;</span>)</span><br><span class="line">			audio = r.listen(source)</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			message = r.recognize_google(audio)</span><br><span class="line">			<span class="built_in">print</span>(<span class="string">&quot;ME: &quot;</span>, r.recognize_google(audio))</span><br><span class="line">		<span class="keyword">except</span> sr.UnknownValueError:</span><br><span class="line">			<span class="built_in">print</span>(<span class="string">&quot;Google Web Speech could not understand the audio&quot;</span>)</span><br><span class="line">		<span class="keyword">except</span> sr.Request <span class="keyword">as</span> e:</span><br><span class="line">			<span class="built_in">print</span>(<span class="string">&quot;Could not request results form Google Web service&quot;</span>)</span><br><span class="line">		</span><br><span class="line">		<span class="comment"># generate the response</span></span><br><span class="line">		response = jarvis.chat(message)</span><br><span class="line">		speak(<span class="built_in">str</span>(response))</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Jarvis: &quot;</span>, response)</span><br><span class="line">	<span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;Exiting...&quot;</span>)</span><br><span class="line">		<span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<h1 id="後記"><a href="#後記" class="headerlink" title="後記"></a>後記</h1><p>Github 上的檔案可能會晚點上，下一篇我會寫 Jarvis Beta 版，直接將預訓練好的模型載到電腦裡，越後面的版本呈現的效果越酷炫。</p>
]]></content>
      <tags>
        <tag>Jarvis</tag>
        <tag>Huggingface</tag>
        <tag>gTTS</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>Welcome to Bakersite</title>
    <url>/2024/08/14/Welcome-to-Bakersite/</url>
    <content><![CDATA[<p>這裡會分享一些科技相關的文章，可能有些人會因為不會寫程式而放棄去探索一些領域的內容，然而生成式AI其實可以解決程式能力的問題，希望這裡的內容，能幫助到對科技有興趣的人。文章中的程式碼大多數是由AI進行編寫，這裡的程式碼不是重點，最主要的目的是介紹一些好用得工具或是App。我會盡量將文章寫的淺顯易懂，讓更多人能體驗。</p>
]]></content>
  </entry>
</search>
