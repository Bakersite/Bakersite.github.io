{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/Shadow_with_black.png","path":"images/Shadow_with_black.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"16171df298326275f9a788b1b529359b44bef294","modified":1723700209186},{"_id":"source/_data/styles.styl","hash":"9f24d500bf8eb5e34bcd8725cd7fd48c5b13d1c7","modified":1723686715285},{"_id":"source/_posts/.DS_Store","hash":"f8420da7bdae8d9e9bc6a66e99944809bca2748d","modified":1723710824601},{"_id":"source/_data/footer.swig","hash":"51caf6ba389dc86e3d4f4276ce6892fd1f7513ca","modified":1723623448981},{"_id":"source/_posts/Jarvis-Alpha.md","hash":"36e288266ca48b2b3bdc3a585ba544d6a5276c6c","modified":1723710691736},{"_id":"source/_posts/.obsidian/appearance.json","hash":"bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f","modified":1723628375912},{"_id":"source/_posts/.obsidian/app.json","hash":"bf21a9e8fbc5a3846fb05b4fa0859e0917b2202f","modified":1723628375911},{"_id":"source/_posts/Welcome-to-Bakersite.md","hash":"edb15368d82d30e5988154b4ad2dfcbdcb1a0d49","modified":1723628689875},{"_id":"source/_posts/.obsidian/core-plugins.json","hash":"eb138d03157a06efdb791f441be97c256aca472c","modified":1723628375538},{"_id":"source/_posts/.obsidian/core-plugins-migration.json","hash":"688b44c61ce85d9ac421b1a310a72c1348bc9b51","modified":1723628375540},{"_id":"source/_posts/.obsidian/workspace.json","hash":"5ef0fc4575b24a1176abdc987e67567237295a50","modified":1723710113642},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1723622069837},{"_id":"themes/next/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1723622069837},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1723622069839},{"_id":"themes/next/.DS_Store","hash":"ecbd8ad1e018b2dae40d16dd8edf9cab615538e9","modified":1723625119611},{"_id":"themes/next/.gitignore","hash":"56f3470755c20311ddd30d421b377697a6e5e68b","modified":1723622069839},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1723622069837},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1723622069839},{"_id":"themes/next/package.json","hash":"62fad6de02adbbba9fb096cbe2dcc15fe25f2435","modified":1723622069855},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1723622069839},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"aa4cb7aff595ca628cb58160ee1eee117989ec4e","modified":1723622069837},{"_id":"themes/next/README.md","hash":"9b4b7d66aca47f9c65d6321b14eef48d95c4dff1","modified":1723622069839},{"_id":"themes/next/gulpfile.js","hash":"1b4fc262b89948937b9e3794de812a7c1f2f3592","modified":1723622069843},{"_id":"themes/next/_config.yml","hash":"34b1ee71ff540987f264b978097f7b58786ffc30","modified":1723711634886},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1a435c20ae8fa183d49bbf96ac956f7c6c25c8af","modified":1723622069838},{"_id":"themes/next/.github/issue-close-app.yml","hash":"7cba457eec47dbfcfd4086acd1c69eaafca2f0cd","modified":1723622069838},{"_id":"themes/next/.github/config.yml","hash":"1d3f4e8794986817c0fead095c74f756d45f91ed","modified":1723622069838},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1723622069840},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"e554931b98f251fd49ff1d2443006d9ea2c20461","modified":1723622069838},{"_id":"themes/next/.github/release-drafter.yml","hash":"3cc10ce75ecc03a5ce86b00363e2a17eb65d15ea","modified":1723622069839},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"fca600ddef6f80c5e61aeed21722d191e5606e5b","modified":1723622069838},{"_id":"themes/next/.github/stale.yml","hash":"fdf82de9284f8bc8e0b0712b4cc1cb081a94de59","modified":1723622069839},{"_id":"themes/next/.github/lock.yml","hash":"61173b9522ebac13db2c544e138808295624f7fd","modified":1723622069838},{"_id":"themes/next/.github/support.yml","hash":"d75db6ffa7b4ca3b865a925f9de9aef3fc51925c","modified":1723622069839},{"_id":"themes/next/.github/mergeable.yml","hash":"0ee56e23bbc71e1e76427d2bd255a9879bd36e22","modified":1723622069839},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"c7a994b9542040317d8f99affa1405c143a94a38","modified":1723622069841},{"_id":"themes/next/docs/MATH.md","hash":"d645b025ec7fb9fbf799b9bb76af33b9f5b9ed93","modified":1723622069841},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1723622069840},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1723622069841},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1723622069841},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"8b6e4b2c9cfcb969833092bdeaed78534082e3e6","modified":1723622069842},{"_id":"themes/next/docs/DATA-FILES.md","hash":"cddbdc91ee9e65c37a50bec12194f93d36161616","modified":1723622069841},{"_id":"themes/next/layout/_layout.swig","hash":"6a6e92a4664cdb981890a27ac11fd057f44de1d5","modified":1723622069846},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"94dc3404ccb0e5f663af2aa883c1af1d6eae553d","modified":1723622069841},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1723622069841},{"_id":"themes/next/layout/archive.swig","hash":"e4e31317a8df68f23156cfc49e9b1aa9a12ad2ed","modified":1723622069854},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1723622069858},{"_id":"themes/next/layout/category.swig","hash":"1bde61cf4d2d171647311a0ac2c5c7933f6a53b0","modified":1723622069855},{"_id":"themes/next/layout/index.swig","hash":"7f403a18a68e6d662ae3e154b2c1d3bbe0801a23","modified":1723622069855},{"_id":"themes/next/layout/post.swig","hash":"2f6d992ced7e067521fdce05ffe4fd75481f41c5","modified":1723622069855},{"_id":"themes/next/layout/tag.swig","hash":"0dfb653bd5de980426d55a0606d1ab122bd8c017","modified":1723622069855},{"_id":"themes/next/languages/en.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1723622069844},{"_id":"themes/next/languages/default.yml","hash":"45bc5118828bdc72dcaa25282cd367c8622758cb","modified":1723622069844},{"_id":"themes/next/layout/page.swig","hash":"db581bdeac5c75fabb0f17d7c5e746e47f2a9168","modified":1723622069855},{"_id":"themes/next/languages/es.yml","hash":"c64cf05f356096f1464b4b1439da3c6c9b941062","modified":1723622069844},{"_id":"themes/next/languages/fa.yml","hash":"3676b32fda37e122f3c1a655085a1868fb6ad66b","modified":1723622069844},{"_id":"themes/next/source/.DS_Store","hash":"0c63622961463a68ef77069a53ad864422e20d45","modified":1723625148660},{"_id":"themes/next/languages/id.yml","hash":"572ed855d47aafe26f58c73b1394530754881ec2","modified":1723622069845},{"_id":"themes/next/languages/de.yml","hash":"74c59f2744217003b717b59d96e275b54635abf5","modified":1723622069844},{"_id":"themes/next/languages/hu.yml","hash":"b1ebb77a5fd101195b79f94de293bcf9001d996f","modified":1723622069844},{"_id":"themes/next/languages/fr.yml","hash":"752bf309f46a2cd43890b82300b342d7218d625f","modified":1723622069844},{"_id":"themes/next/languages/ja.yml","hash":"0cf0baa663d530f22ff380a051881216d6adcdd8","modified":1723622069845},{"_id":"themes/next/languages/nl.yml","hash":"5af3473d9f22897204afabc08bb984b247493330","modified":1723622069845},{"_id":"themes/next/languages/ko.yml","hash":"0feea9e43cd399f3610b94d755a39fff1d371e97","modified":1723622069845},{"_id":"themes/next/languages/pt.yml","hash":"718d131f42f214842337776e1eaddd1e9a584054","modified":1723622069845},{"_id":"themes/next/languages/pt-BR.yml","hash":"67555b1ba31a0242b12fc6ce3add28531160e35b","modified":1723622069845},{"_id":"themes/next/languages/ru.yml","hash":"e993d5ca072f7f6887e30fc0c19b4da791ca7a88","modified":1723622069845},{"_id":"themes/next/languages/tr.yml","hash":"2b041eeb8bd096f549464f191cfc1ea0181daca4","modified":1723622069845},{"_id":"themes/next/languages/uk.yml","hash":"3a6d635b1035423b22fc86d9455dba9003724de9","modified":1723622069846},{"_id":"themes/next/languages/it.yml","hash":"44759f779ce9c260b895532de1d209ad4bd144bf","modified":1723622069845},{"_id":"themes/next/languages/ar.yml","hash":"9815e84e53d750c8bcbd9193c2d44d8d910e3444","modified":1723622069844},{"_id":"themes/next/languages/vi.yml","hash":"93393b01df148dcbf0863f6eee8e404e2d94ef9e","modified":1723622069846},{"_id":"themes/next/languages/zh-CN.yml","hash":"a1f15571ee7e1e84e3cc0985c3ec4ba1a113f6f8","modified":1723622069846},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.md","hash":"c3e6b8196c983c40fd140bdeca012d03e6e86967","modified":1723622069838},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.md","hash":"12d99fb8b62bd9e34d9672f306c9ae4ace7e053e","modified":1723622069838},{"_id":"themes/next/.github/ISSUE_TEMPLATE/question.md","hash":"53df7d537e26aaf062d70d86835c5fd8f81412f3","modified":1723622069838},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.md","hash":"d3efc0df0275c98440e69476f733097916a2d579","modified":1723622069838},{"_id":"themes/next/languages/zh-TW.yml","hash":"8c09da7c4ec3fca2c6ee897b2eea260596a2baa1","modified":1723622069846},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"0bd2d696f62a997a11a7d84fec0130122234174e","modified":1723622069842},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1723622069842},{"_id":"themes/next/languages/zh-HK.yml","hash":"3789f94010f948e9f23e21235ef422a191753c65","modified":1723622069846},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"5237a368ab99123749d724b6c379415f2c142a96","modified":1723622069842},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"ca1030efdfca5e20f9db2e7a428998e66a24c0d0","modified":1723622069843},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1723622069843},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"8b18f84503a361fc712b0fe4d4568e2f086ca97d","modified":1723622069843},{"_id":"themes/next/docs/ru/README.md","hash":"85dd68ed1250897a8e4a444a53a68c1d49eb7e11","modified":1723622069842},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"34b88784ec120dfdc20fa82aadeb5f64ef614d14","modified":1723622069842},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"d3f03be036b75dc71cf3c366cd75aee7c127c874","modified":1723622069843},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"fb23b85db6f7d8279d73ae1f41631f92f64fc864","modified":1723622069842},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"9c8dc0b8170679cdc1ee9ee8dbcbaebf3f42897b","modified":1723622069846},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b92585d251f1f9ebe401abb5d932cb920f9b8b10","modified":1723622069843},{"_id":"themes/next/docs/zh-CN/README.md","hash":"c038629ff8f3f24e8593c4c8ecf0bef3a35c750d","modified":1723622069843},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"71655ca21907e9061b6e8ac52d0d8fbf54d0062b","modified":1723622069847},{"_id":"themes/next/layout/_partials/comments.swig","hash":"db6ab5421b5f4b7cb32ac73ad0e053fdf065f83e","modified":1723622069847},{"_id":"themes/next/layout/_partials/footer.swig","hash":"4369b313cbbeae742cb35f86d23d99d4285f7359","modified":1723622069847},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"d9ce7331c1236bbe0a551d56cef2405e47e65325","modified":1723622069843},{"_id":"themes/next/layout/_partials/languages.swig","hash":"ba9e272f1065b8f0e8848648caa7dea3f02c6be1","modified":1723622069848},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1723622069850},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1723622069850},{"_id":"themes/next/layout/_macro/post.swig","hash":"090b5a9b6fca8e968178004cbd6cff205b7eba57","modified":1723622069847},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1723622069850},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1723622069848},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1723622069851},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1723622069853},{"_id":"themes/next/scripts/events/index.js","hash":"5743cde07f3d2aa11532a168a652e52ec28514fd","modified":1723622069855},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1723622069851},{"_id":"themes/next/scripts/helpers/engine.js","hash":"bdb424c3cc0d145bd0c6015bb1d2443c8a9c6cda","modified":1723622069857},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"311e5eceec9e949f1ea8d623b083cec0b8700ff2","modified":1723622069853},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"958e86b2bd24e4fdfcbf9ce73e998efe3491a71f","modified":1723622069858},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"4d2c93c66e069852bb0e3ea2e268d213d07bfa3f","modified":1723622069850},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"703bdd142a671b4b67d3d9dfb4a19d1dd7e7e8f7","modified":1723622069857},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"5e11f30ddb5093a88a687446617a46b048fa02e5","modified":1723622069858},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"2731e262a6b88eaee2a3ca61e6a3583a7f594702","modified":1723622069853},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1723622069857},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1723622069857},{"_id":"themes/next/scripts/filters/post.js","hash":"44ba9b1c0bdda57590b53141306bb90adf0678db","modified":1723622069857},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f1826ade2d135e2f60e2d95cb035383685b3370c","modified":1723622069858},{"_id":"themes/next/scripts/filters/locals.js","hash":"b193a936ee63451f09f8886343dcfdca577c0141","modified":1723622069857},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1723622069858},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"94e0bbc7999b359baa42fa3731bdcf89c79ae2b3","modified":1723622069858},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"d902fd313e8d35c3cc36f237607c2a0536c9edf1","modified":1723622069858},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"b782eb2e34c0c15440837040b5d65b093ab6ec04","modified":1723622069852},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1723622069858},{"_id":"themes/next/scripts/tags/pdf.js","hash":"8c613b39e7bff735473e35244b5629d02ee20618","modified":1723622069859},{"_id":"themes/next/scripts/tags/tabs.js","hash":"93d8a734a3035c1d3f04933167b500517557ba3e","modified":1723622069859},{"_id":"themes/next/scripts/tags/button.js","hash":"8c6b45f36e324820c919a822674703769e6da32c","modified":1723622069858},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1723622069859},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1723622069859},{"_id":"themes/next/scripts/helpers/font.js","hash":"40cf00e9f2b7aa6e5f33d412e03ed10304b15fd7","modified":1723622069857},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1723622069870},{"_id":"themes/next/source/css/main.styl","hash":"a3a3bbb5a973052f0186b3523911cb2539ff7b88","modified":1723622069870},{"_id":"themes/next/source/css/_mixins.styl","hash":"e31a557f8879c2f4d8d5567ee1800b3e03f91f6e","modified":1723622069867},{"_id":"themes/next/source/css/_colors.styl","hash":"a8442520f719d3d7a19811cb3b85bcfd4a596e1f","modified":1723622069859},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1723622069870},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1723622069870},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1723622069871},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1723622069871},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1723622069871},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1723622069871},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1723622069871},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1723622069871},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1723622069871},{"_id":"themes/next/source/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1723622069872},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1723622069871},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1723622069871},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1723622069872},{"_id":"themes/next/source/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1723622069872},{"_id":"themes/next/source/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1723622069872},{"_id":"themes/next/source/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1723622069872},{"_id":"themes/next/source/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1723622069873},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"000bad572d76ee95d9c0a78f9ccdc8d97cc7d4b4","modified":1723622069847},{"_id":"themes/next/source/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1723622069872},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"c70f8e71e026e878a4e9d5ab3bbbf9b0b23c240c","modified":1723622069847},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"810d544019e4a8651b756dd23e5592ee851eda71","modified":1723622069847},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"9440d8a3a181698b80e1fa47f5104f4565d8cdf3","modified":1723622069848},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"954ad71536b6eb08bd1f30ac6e2f5493b69d1c04","modified":1723622069849},{"_id":"themes/next/layout/_partials/post/post-followme.swig","hash":"ceba16b9bd3a0c5c8811af7e7e49d0f9dcb2f41e","modified":1723622069849},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"7dbe93b8297b746afb89700b4d29289556e85267","modified":1723622069848},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1723622069849},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"2b1a73556595c37951e39574df5a3f20b2edeaef","modified":1723622069849},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1723622069849},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"d31f896680a6c2f2c3f5128b4d4dd46c87ce2130","modified":1723622069848},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1723622069848},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1723622069873},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"ae2261bea836581918a1c2b0d1028a78718434e0","modified":1723622069848},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"2be50f9bfb1c56b85b3b6910a7df27f51143632c","modified":1723622069849},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"c46849e0af8f8fb78baccd40d2af14df04a074af","modified":1723622069850},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"48430bd03b8f19c9b8cdb2642005ed67d56c6e0b","modified":1723622069849},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"9b7a66791d7822c52117fe167612265356512477","modified":1723622069848},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1723622069850},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1723622069850},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1723622069851},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"077b5d66f6309f2e7dcf08645058ff2e03143e6c","modified":1723622069850},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"f48a6a8eba04eb962470ce76dd731e13074d4c45","modified":1723622069849},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1723622069851},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1723622069851},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b14908644225d78c864cd0a9b60c52407de56183","modified":1723622069852},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"2fa2b51d56bfac6a1ea76d651c93b9c20b01c09b","modified":1723622069851},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"f7a9eca599a682479e8ca863db59be7c9c7508c8","modified":1723622069852},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1723622069851},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1723622069851},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"be0a8eccf1f6dc21154af297fc79555343031277","modified":1723622069852},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"f39a5bf3ce9ee9adad282501235e0c588e4356ec","modified":1723622069852},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"d6ceb70648555338a80ae5724b778c8c58d7060d","modified":1723622069852},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1723622069853},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1723622069853},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"82f5b6822aa5ec958aa987b101ef860494c6cf1f","modified":1723622069852},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"4b1986e43d6abce13450d2b41a736dd6a5620a10","modified":1723622069854},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"d56d5af427cdfecc33a0f62ee62c056b4e33d095","modified":1723622069854},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1723622069854},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"5f6a966c509680dbfa70433f9d658cee59c304d7","modified":1723622069854},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"d35a999d67f4c302f76fdf13744ceef3c6506481","modified":1723622069853},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1723622069853},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"ecf751321e799f0fb3bf94d049e535130e2547aa","modified":1723622069853},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1723622069854},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1723622069856},{"_id":"themes/next/scripts/events/lib/config.js","hash":"d34c6040b13649714939f59be5175e137de65ede","modified":1723622069856},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"f910618292c63871ca2e6c6e66c491f344fa7b1f","modified":1723622069852},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"b26ac2bfbe91dd88267f8b96aee6bb222b265b7a","modified":1723622069854},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"2486f3e0150c753e5f3af1a3665d074704b8ee2c","modified":1723622069856},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1723622069852},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"7f8b92913d21070b489457fa5ed996d2a55f2c32","modified":1723622069856},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"4c0c99c7e0f00849003dfce02a131104fb671137","modified":1723622069856},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"f233d8d0103ae7f9b861344aa65c1a3c1de8a845","modified":1723622069856},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"d30b0e255a8092043bac46441243f943ed6fb09b","modified":1723622069854},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"d5fefc31fba4ab0188305b1af1feb61da49fdeb0","modified":1723622069857},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1723622069856},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"6cbd85f9433c06bae22225ccf75ac55e04f2d106","modified":1723622069857},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1723622069856},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"f3c43664a071ff3c0b28bd7e59b5523446829576","modified":1723622069854},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"612ec843372dae709acb17112c1145a53450cc59","modified":1723622069870},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"62df49459d552bbf73841753da8011a1f5e875c8","modified":1723622069870},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"f4e694e5db81e57442c7e34505a416d818b3044a","modified":1723622069869},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1723622069872},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"f70be8e229da7e1715c11dd0e975a2e71e453ac8","modified":1723622069869},{"_id":"themes/next/source/css/_variables/base.styl","hash":"818508748b7a62e02035e87fe58e75b603ed56dc","modified":1723622069870},{"_id":"themes/next/source/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1723622069872},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"ca5e70662dcfb261c25191cc5db5084dcf661c76","modified":1723622069859},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"a47725574e1bee3bc3b63b0ff2039cc982b17eff","modified":1723622069859},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1723622069875},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"8e7b57a72e757cf95278239641726bb2d5b869d1","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"2e3bf7baf383c9073ec5e67f157d3cb3823c0957","modified":1723622069862},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"681d33e3bc85bdca407d93b134c089264837378c","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"a1690e035b505d28bdef2b4424c13fc6312ab049","modified":1723622069864},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1723622069875},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"4cbc563ef5b3f12785e411b2f14bbc5a1013053e","modified":1723693297835},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"f0131db6275ceaecae7e1a6a3798b8f89f6c850d","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"93db5dafe9294542a6b5f647643cb9deaced8e06","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"2b2e7b5cea7783c9c8bb92655e26a67c266886f0","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"f6516d0f7d89dc7b6c6e143a5af54b926f585d82","modified":1723622069867},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1723622069869},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"bb7ace23345364eb14983e860a7172e1683a4c94","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"7104b9cef90ca3b140d7a7afcf15540a250218fc","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"6136da4bbb7e70cec99f5c7ae8c7e74f5e7c261a","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"85da2f3006f4bef9a2199416ecfab4d288f848c4","modified":1723622069869},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1723622069868},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"70a4324b70501132855b5e59029acfc5d3da1ebd","modified":1723622069869},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"44f47c88c06d89d06f220f102649057118715828","modified":1723622069869},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1723622069869},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"e282df938bd029f391c466168d0e68389978f120","modified":1723622069869},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"e740deadcfc4f29c5cb01e40f9df6277262ba4e3","modified":1723622069869},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"b1f0fab7344a20ed6748b04065b141ad423cf4d9","modified":1723622069865},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"0b2c4b78eead410020d7c4ded59c75592a648df8","modified":1723622069865},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"18ce72d90459c9aa66910ac64eae115f2dde3767","modified":1723622069866},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"a2e9e00962e43e98ec2614d6d248ef1773bb9b78","modified":1723622069865},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1723622069866},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"a54708fd9309b4357c423a3730eb67f395344a5e","modified":1723622069856},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1723622069867},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1723622069866},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1723622069866},{"_id":"themes/next/source/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1723622069873},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"e771dcb0b4673e063c0f3e2d73e7336ac05bcd57","modified":1723622069860},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1723622069874},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"d21d4ac1982c13d02f125a67c065412085a92ff2","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1723622069862},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"b49e9fbd3c182b8fc066b8c2caf248e3eb748619","modified":1723622069862},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"e75693f33dbc92afc55489438267869ae2f3db54","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"9f0b93d109c9aec79450c8a0cf4a4eab717d674d","modified":1723622069862},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"902569a9dea90548bec21a823dd3efd94ff7c133","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1723622069862},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ded41fd9d20a5e8db66aaff7cc50f105f5ef2952","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f49ca072b5a800f735e8f01fc3518f885951dd8e","modified":1723622069860},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9a878d0119785a2316f42aebcceaa05a120b9a7a","modified":1723622069862},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"1e4190c10c9e0c9ce92653b0dbcec21754b0b69d","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"65cb6edb69e94e70e3291e9132408361148d41d5","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"d114b2a531129e739a27ba6271cfe6857aa9a865","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"72d495a88f7d6515af425c12cbc67308a57d88ea","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1723622069862},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"6a97bcfa635d637dc59005be3b931109e0d1ead5","modified":1723622069861},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"a760ee83ba6216871a9f14c5e56dc9bd0d9e2103","modified":1723622069862},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"e7a9fdb6478b8674b1cdf94de4f8052843fb71d9","modified":1723622069863},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e2d606f1ac343e9be4f15dbbaf3464bc4df8bf81","modified":1723622069863},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1723622069861},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"45a239edca44acecf971d99b04f30a1aafbf6906","modified":1723622069863},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b2fc519828fe89a1f8f03ff7b809ad68cd46f3d7","modified":1723622069863},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"5f432a6ed9ca80a413c68b00e93d4a411abf280a","modified":1723622069863},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1723622069863},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"1f0e7fbe80956f47087c2458ea880acf7a83078b","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"44487d9ab290dc97871fa8dd4487016deb56e123","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"fa0222197b5eee47e18ac864cdc6eac75678b8fe","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"a960a2dd587b15d3b3fe1b59525d6fa971c6a6ec","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"a05a4031e799bc864a4536f9ef61fe643cd421af","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"a793cfff86ad4af818faef04c18013077873f8f0","modified":1723622069863},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1723622069865},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1723622069864},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"2a47f8a6bb589c2fb635e6c1e4a2563c7f63c407","modified":1723622069865},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"a9cd93c36bae5af9223e7804963096274e8a4f03","modified":1723622069865},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"454a4aebfabb4469b92a8cbb49f46c49ac9bf165","modified":1723622069863},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"35c871a809afa8306c8cde13651010e282548bc6","modified":1723622069865},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"f71a3e86c05ea668b008cf05a81f67d92b6d65e4","modified":1723622069865},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1723622069865},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"1d2778ca5aeeeafaa690dc2766b01b352ab76a02","modified":1723622069866},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"d7fce4b51b5f4b7c31d93a9edb6c6ce740aa0d6b","modified":1723622069866},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"709d10f763e357e1472d6471f8be384ec9e2d983","modified":1723622069866},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"f23670f1d8e749f3e83766d446790d8fd9620278","modified":1723622069867},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1723622069867},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"b49c64f8e9a6ca1c45c0ba98febf1974fdd03616","modified":1723622069867},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"e4d9a77ffe98e851c1202676940097ba28253313","modified":1723622069867},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1723622069866},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1723622069874},{"_id":"themes/next/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1723622069874},{"_id":"themes/next/source/images/Shadow_with_black.png","hash":"9f413252a491813d1b98e5589d036e48494c340d","modified":1723625178220},{"_id":"public/search.xml","hash":"3a03c9178111706a6d9787b5dc2f58e479b3e643","modified":1723712175001},{"_id":"public/2024/08/14/Welcome-to-Bakersite/index.html","hash":"097d6e7b941eaca1780440ee9388ce3de7fe425e","modified":1723712175001},{"_id":"public/2024/08/15/Jarvis-Alpha/index.html","hash":"048ab88e90f678b9a9cdf15a17aa6ba4cdc5a1fb","modified":1723712175001},{"_id":"public/archives/index.html","hash":"a2bf9a1035f8aad8f6233492ccb5d5682fbf8601","modified":1723712175001},{"_id":"public/archives/2024/index.html","hash":"1ad288ecc30e7594fd8f3b8b9864b350e032c9fa","modified":1723712175001},{"_id":"public/archives/2024/08/index.html","hash":"27ae7d0f1c7ba1366047b93f9bcddd1105340113","modified":1723712175001},{"_id":"public/tags/Jarvis/index.html","hash":"ede33e4deabd4a77f1f65210b540afb7edeb6ce3","modified":1723712175001},{"_id":"public/tags/AI/index.html","hash":"dd9c73d9448f85d781d8398f996c4c2f9f483053","modified":1723712175001},{"_id":"public/tags/gTTS/index.html","hash":"71170bf0cc866fd26c76e3244068bd94b80fda0b","modified":1723712175001},{"_id":"public/tags/Huggingface/index.html","hash":"fd156db8e8c6469c82f22d4994d84d2cfe2dfc33","modified":1723712175001},{"_id":"public/index.html","hash":"6979b189312a197b63ff096c086fbf31c038b014","modified":1723712175001},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1723712175001},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1723712175001},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1723712175001},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1723712175001},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1723712175001},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1723712175001},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1723712175001},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1723712175001},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1723712175001},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1723712175001},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1723712175001},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1723712175001},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"260bb01acd44d88dcb7f501a238ab968f86bef9e","modified":1723712175001},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1723712175001},{"_id":"public/js/algolia-search.js","hash":"498d233eb5c7af6940baf94c1a1c36fdf1dd2636","modified":1723712175001},{"_id":"public/js/bookmark.js","hash":"9734ebcb9b83489686f5c2da67dc9e6157e988ad","modified":1723712175001},{"_id":"public/css/main.css","hash":"a2b767b8c617477a48ad60cbb8fd94c0f6567822","modified":1723712175001},{"_id":"public/js/next-boot.js","hash":"a1b0636423009d4a4e4cea97bcbf1842bfab582c","modified":1723712175001},{"_id":"public/js/local-search.js","hash":"35ccf100d8f9c0fd6bfbb7fa88c2a76c42a69110","modified":1723712175001},{"_id":"public/js/motion.js","hash":"72df86f6dfa29cce22abeff9d814c9dddfcf13a9","modified":1723712175001},{"_id":"public/js/utils.js","hash":"730cca7f164eaf258661a61ff3f769851ff1e5da","modified":1723712175001},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1723712175001},{"_id":"public/js/schemes/pisces.js","hash":"0ac5ce155bc58c972fe21c4c447f85e6f8755c62","modified":1723712175001},{"_id":"public/js/schemes/muse.js","hash":"1eb9b88103ddcf8827b1a7cbc56471a9c5592d53","modified":1723712175001},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1723712175001},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"0038dc97c79451578b7bd48af60ba62282b4082b","modified":1723712175001},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"509988477da79c146cb93fb728405f18e923c2de","modified":1723712175001},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"75a88815c47a249eadb5f0edc1675957f860cca7","modified":1723712175001},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1723712175001},{"_id":"public/images/Shadow_with_black.png","hash":"9f413252a491813d1b98e5589d036e48494c340d","modified":1723712175001}],"Category":[],"Data":[{"_id":"footer","data":"<script color=\"0,0,255\" opacity=\"0.5\" zIndex=\"-1\" count=\"99\" src=\"https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\"></script>\n\n"},{"_id":"styles","data":".post-toc .nav .nav-child {\n  display: block;\n}\n.post-toc ol {\n  font-size: 13px;\n}\n"}],"Page":[],"Post":[{"layout":"posts","title":"Jarvis Alpha","date":"2024-08-15T08:20:45.000Z","_content":"# 前言\n語音助理最廣為人知的應該是 Siri 以及 Alexa 了，而在電影 Iron man 中，有個 AI 叫做 J.A.R.V.I.S，專門幫助 Tony Stark 完成各種任務。雖然電影後面他發生了一些事，導致被另一個叫 Friday 的 AI 取代，有興趣的可以去觀看原作。其實我一直以來都很想有個語音AI，協助我處理各種事。兩年前我曾嘗試用 Open AI 的 ChatGPT API，由於 Open AI 訓練完 GPT3 模型之後，開始從開源逐漸走向收費，而 ChatGPT 的 API 免費版有用量限制，最後我專案還沒完成，卻已經用光所有的額度了。曾經有想過要自己訓練模型，但看著桌上的電腦，又默默地放下這個念頭，現階段訓練 AI 需要的硬體設備對我來說是遙不可及。但經過了兩年的時間，越來越多公司投入 AI 領域而且也「開源」了許多模型，也就是說不需要付費便能使用的 AI 模型。Jarvis 版本的命名採拉丁字母的順序，依照 Alpha, Beta, Gama.... 命名下去。這篇是 Jarvis Alpha 版本，我之後會陸續發部改良後的版本，雖然都叫 Jarvis 但其實使用的工具幾乎不一樣。Jarvis Alpha 版是以 Pyhon 進行編寫，我會將專案放在 [Jarvis-Alpha](<https://github.com/Bakersite/Jarvis-Alpha.git>) 。\n\n# Huggingface 的工具\n## HuggingChat\n這邊要介紹 [Huggingface]( <https://huggingface.co/> )，這是一個存放很多開源模型的平台，他除了有模型以外，也提供深度學習框架，有興趣的可以去探索一下，這邊會著墨在他底下一個叫 [HuggingChat](<https://huggingface.co/chat/>) 的生成式 AI 服務。由於在 Alpha 版中尚未用到使用 Huggingface 上的模型，因此有關模型的取用會留到 Beta 版在說明。\n\nHuggingChat 類似於大家熟悉的 ChatGPT ，比較不一樣在 HuggingChat 有許多種模型可以選擇。HuggingChat 也可以自定義 AI 的目的，像是以資深的軟體工程師來修正程式碼，可以在建立對話時便設定好，不需要每次都發送指定 AI 角色的 prompt。\n\n實作時會需要 Huggingface 的帳號，若要實作，可以先申請。\n\nP.S. 此文章發布時有一款模型 Llama3.1，由 Meta 訓練的開源模型，「據說」可以匹敵 Open AI 的 gpt-4o mini，各位可以玩玩看。\n\n## Hugging Chat API\n[Hugging-Chat-API](<https://github.com/Soulter/hugging-chat-api>)它是一個大佬寫的，並不是 Huggingface 官方的 API，在 Alpha 版中我會利用它來連接 Hugging Chat 當作 Jarvis 的大腦，若有要實作的請先下載，建議參閱網站的說明文件，下面的安裝參考會比較簡潔。說明文件有詳細的指引，大家也可以試試用他的說明指引，自己做一個語音 AI。\n\n# 實作\n## 流程\n```mermaid\nflowchart LR\nA(Speech to Text) \nB(Hugging Chat API) \nC[(Hugging Chat server)]\nD(Text to Speech)\nA --> B --> C --> D --> A\n\n```\n\n語音 AI 主要可以拆成三個步驟。\n1. 語音辨識成文字 \n2. 由生成式 AI 當作大腦進行理解 \n3. 將生成的文字合成語音並播放\n\n## 語音辨識\n在這裡我們使用 Python 一個叫 [Speech Recognition](<https://pypi.org/project/SpeechRecognition/>) 的工具，利用這工具將語音轉換成文字。以下是簡易的安裝方法，完整說明可以參閱官方文件。\n```bash\npip install SpeechRecognition\n```\n\n接下來只需要在 python 中導入模組即可。\n\n```python\nimport speech_recognition as sr\n```\n\n先初始化麥克風（建議放在程式碼開頭）接著我們將音訊輸入源調成麥克風，這裡會用 Google 的 Speech to Text 服務，將語音轉成文字，並存入 message 這個變數裡面。這裡會用 try, except 來處理無法辨識語音及連線到 Google 伺服器的錯誤（這邊我沒有將 Google 伺服器回彈的錯誤碼輸出，可以自己更改程式，或是直接在終端機查看）。\n```python\n# initialize the recognizer\nr = sr.Recognizer()\n\n# use the microphone as the source for input\nwith sr.Microphone() as source:                             # 設定麥克風為音訊輸入源\n\tprint(\"Adjusting for ambient noise, please wait...\")\n\tr.adjust_for_ambient_noise(source)                      # 處理背景雜音\n\tprint(\"Say something!\")\n\taudio = r.listen(source)                                # 開始收音\n\t\n\ttry:\n\t\tmessage = r.recognize_google(audio)                 # 將語音轉成文字\n\t\tprint(\"ME: \", r.recognize_google(audio))\n\texcept sr.UnknownValueError:                            # 語音無法辨識\n\t\tprint(\"Google Web Speech could not understand the audio\")\n\texcept sr.Request as e:                                 # google伺服器錯誤訊息\n\t\tprint(\"Could not request results form Google Web service\")\n```\n\n## Brain\n確認已安裝 Hugging Chat API。\n```bash\npip instal hugchat\n```\n\n接著將 Hugging Chat 導入到程式碼。\n```python\nfrom hugchat import hugchat\nfrom hugchat.login import Login\n```\n\n導入完後，確認已申請 Huggingface 的帳號，並將 email, passwd 分別輸入申請時的電子郵件帳號及 Huggingface 的密碼，這是用來在 python 程式中登入 Huggingface 帳號來使用 Hugging Chat的功能。\n```python\n# login\nemail = \"\"                                                  # 請輸入自己的email\npasswd = \"\"                                                 # 請輸入自己的密碼\nsign = Login(email, passwd)\ncookies = sign.login()\n```\n\n登入完後就可以啟動它了，這邊所使用 jarvis 變數可以改成任何名字。\n```python\n# activate\njarvis = hugchat.ChatBot(cookies=cookies.get_dict())\n```\n\n這邊建議將 login 和 activate 這兩個片段放在程式碼前端，完整程式碼我會放在最尾端。\n接著我們在語音辨識的程式碼後面將辨識好的文字送給 Hugging Chat 生成回答。\n```python\nresponse = jarvis.chat(message)\n```\n\n## 語音合成\n終於來到語音合成。這裡使用的語音合成模型會是 Google 的 gTTS，語音合成模型很多，也可以使用pytts 或是 OpenAI 的whisperAPI（這要付費，有一個開源模型也是whisper，是 OpenAI 訓練的，但他只有與語音轉文字而已，在 Gama 版我會介紹並使用）。除了 gTTS 我還會再使用 pydub 方便合成處理及播放音訊。\n安裝 [gTTS](<https://pypi.org/project/gTTS/>) 及 [pydub](<https://pypi.org/project/pydub/>)可以參閱說明文件。\n```bash\npip install gTTS pydub\n```\n\n接著只要將 gTTS 導入 python 程式就可以了。這裡我們要使用 pydub 裡的 AudioSegment 及 play 而已，以此只導入這兩個函式。\n```python\nfrom gtts import gTTS\n\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n```\n\n導入完工具後，接下來進行語音合成。設定合成的語言是英文，再把檔案存成 mp3 格式，但因為在之後用 pygame 編寫 GUI (使用者介面）時，只支援 16 位的 PCM wav 檔，因此要做轉檔的動作，有關 GUI 介面我會再找時間發一篇文章。 \n```python\ndef speak(text):\n\ttts = gTTS(text=text, lang='en') # 合成語言設定\n\ttts.save(\"response.mp3\")         # 音檔為 mp3 \n\t\n\t# 轉換為 16 位 PCM 格式的 WAV 文件\n\taudio = AudioSegment.from_mp3(\"response.mp3\")\n\taudio = audio.set_frame_rate(44100).set_channels(2).set_sample_width(2)\n\taudio.export(\"response.wav\", format='wav')\n```\n\n編寫完函式，只要將 Hugging Chat 產生的回答放入 speak 函式中就可以生成音檔了。最後在用play 播放音檔，我會習慣在語音播放完後輸出文字，確認講的內容，這行可以自行刪減。\n```python\nspeak(str(response))           # 強制轉型 string 格式怕 response 產生的文字格式不是字串\nplay(AudioSegment.from_wav(\"response.wav\"))\nprint(response)\n```\n\n# 完整的程式碼\n我在這裡加上了迴圈及停止方法（按下 Ctrl + C）可以終止程式。\n```python\nimport speech_recognition as sr\nfrom hugchat import hugchat\nfrom hugchat.login import Login\nfrom gtts import gTTS\nfrom pydub import AudioSegment\n\n# speaking\ndef speak(text):\n\ttts = gTTS(text=text, lang='en')\n\ttts.save(\"response.mp3\")\n\n\t# 轉換為 16 位 PCM 格式的 WAV 文件\n\taudio = AudioSegment.from_mp3(\"response.mp3\")\n\taudio = audio.set_frame_rate(44100).set_channels(2).set_sample_width(2)\n\taudio.export(\"response.wav\", format='wav')\n\n\n# initialize the recognizer\nr = sr.Recognizer()\n\n# log in\nemail = \"\"\npasswd = \"\"\nsign = Login(email, passwd)\ncookies = sign.login()\n\n# activate bot\njarvis = hugchat.ChatBot(cookies=cookies.get_dict())\n\n# generate response\nwhile(True):\n\ttry:\n\t\t# use the microphone as the source for input\n\t\twith sr.Microphone() as source:\n\t\t\tprint(\"Adjusting for ambient noise, please wait...\")\n\t\t\tr.adjust_for_ambient_noise(source)\n\t\t\tprint(\"Say something!\")\n\t\t\taudio = r.listen(source)\n\t\t\n\t\ttry:\n\t\t\tmessage = r.recognize_google(audio)\n\t\t\tprint(\"ME: \", r.recognize_google(audio))\n\t\texcept sr.UnknownValueError:\n\t\t\tprint(\"Google Web Speech could not understand the audio\")\n\t\texcept sr.Request as e:\n\t\t\tprint(\"Could not request results form Google Web service\")\n\t\t\n\t\t# generate the response\n\t\tresponse = jarvis.chat(message)\n\t\tspeak(str(response))\n\t\tprint(\"Jarvis: \", response)\n\texcept KeyboardInterrupt:\n\t\tprint(\"Exiting...\")\n\t\tbreak\n```\n\n# 後記\nGithub 上的檔案可能會晚點上，下一篇我會寫 Jarvis Beta 版，直接將預訓練好的模型載到電腦裡，越後面的版本呈現的效果越酷炫。","source":"_posts/Jarvis-Alpha.md","raw":"---\nlayout: posts\ntitle: Jarvis Alpha\ndate: 2024-08-15 16:20:45\ntags:\n  - Jarvis\n  - Huggingface\n  - gTTS\n  - AI\n---\n# 前言\n語音助理最廣為人知的應該是 Siri 以及 Alexa 了，而在電影 Iron man 中，有個 AI 叫做 J.A.R.V.I.S，專門幫助 Tony Stark 完成各種任務。雖然電影後面他發生了一些事，導致被另一個叫 Friday 的 AI 取代，有興趣的可以去觀看原作。其實我一直以來都很想有個語音AI，協助我處理各種事。兩年前我曾嘗試用 Open AI 的 ChatGPT API，由於 Open AI 訓練完 GPT3 模型之後，開始從開源逐漸走向收費，而 ChatGPT 的 API 免費版有用量限制，最後我專案還沒完成，卻已經用光所有的額度了。曾經有想過要自己訓練模型，但看著桌上的電腦，又默默地放下這個念頭，現階段訓練 AI 需要的硬體設備對我來說是遙不可及。但經過了兩年的時間，越來越多公司投入 AI 領域而且也「開源」了許多模型，也就是說不需要付費便能使用的 AI 模型。Jarvis 版本的命名採拉丁字母的順序，依照 Alpha, Beta, Gama.... 命名下去。這篇是 Jarvis Alpha 版本，我之後會陸續發部改良後的版本，雖然都叫 Jarvis 但其實使用的工具幾乎不一樣。Jarvis Alpha 版是以 Pyhon 進行編寫，我會將專案放在 [Jarvis-Alpha](<https://github.com/Bakersite/Jarvis-Alpha.git>) 。\n\n# Huggingface 的工具\n## HuggingChat\n這邊要介紹 [Huggingface]( <https://huggingface.co/> )，這是一個存放很多開源模型的平台，他除了有模型以外，也提供深度學習框架，有興趣的可以去探索一下，這邊會著墨在他底下一個叫 [HuggingChat](<https://huggingface.co/chat/>) 的生成式 AI 服務。由於在 Alpha 版中尚未用到使用 Huggingface 上的模型，因此有關模型的取用會留到 Beta 版在說明。\n\nHuggingChat 類似於大家熟悉的 ChatGPT ，比較不一樣在 HuggingChat 有許多種模型可以選擇。HuggingChat 也可以自定義 AI 的目的，像是以資深的軟體工程師來修正程式碼，可以在建立對話時便設定好，不需要每次都發送指定 AI 角色的 prompt。\n\n實作時會需要 Huggingface 的帳號，若要實作，可以先申請。\n\nP.S. 此文章發布時有一款模型 Llama3.1，由 Meta 訓練的開源模型，「據說」可以匹敵 Open AI 的 gpt-4o mini，各位可以玩玩看。\n\n## Hugging Chat API\n[Hugging-Chat-API](<https://github.com/Soulter/hugging-chat-api>)它是一個大佬寫的，並不是 Huggingface 官方的 API，在 Alpha 版中我會利用它來連接 Hugging Chat 當作 Jarvis 的大腦，若有要實作的請先下載，建議參閱網站的說明文件，下面的安裝參考會比較簡潔。說明文件有詳細的指引，大家也可以試試用他的說明指引，自己做一個語音 AI。\n\n# 實作\n## 流程\n```mermaid\nflowchart LR\nA(Speech to Text) \nB(Hugging Chat API) \nC[(Hugging Chat server)]\nD(Text to Speech)\nA --> B --> C --> D --> A\n\n```\n\n語音 AI 主要可以拆成三個步驟。\n1. 語音辨識成文字 \n2. 由生成式 AI 當作大腦進行理解 \n3. 將生成的文字合成語音並播放\n\n## 語音辨識\n在這裡我們使用 Python 一個叫 [Speech Recognition](<https://pypi.org/project/SpeechRecognition/>) 的工具，利用這工具將語音轉換成文字。以下是簡易的安裝方法，完整說明可以參閱官方文件。\n```bash\npip install SpeechRecognition\n```\n\n接下來只需要在 python 中導入模組即可。\n\n```python\nimport speech_recognition as sr\n```\n\n先初始化麥克風（建議放在程式碼開頭）接著我們將音訊輸入源調成麥克風，這裡會用 Google 的 Speech to Text 服務，將語音轉成文字，並存入 message 這個變數裡面。這裡會用 try, except 來處理無法辨識語音及連線到 Google 伺服器的錯誤（這邊我沒有將 Google 伺服器回彈的錯誤碼輸出，可以自己更改程式，或是直接在終端機查看）。\n```python\n# initialize the recognizer\nr = sr.Recognizer()\n\n# use the microphone as the source for input\nwith sr.Microphone() as source:                             # 設定麥克風為音訊輸入源\n\tprint(\"Adjusting for ambient noise, please wait...\")\n\tr.adjust_for_ambient_noise(source)                      # 處理背景雜音\n\tprint(\"Say something!\")\n\taudio = r.listen(source)                                # 開始收音\n\t\n\ttry:\n\t\tmessage = r.recognize_google(audio)                 # 將語音轉成文字\n\t\tprint(\"ME: \", r.recognize_google(audio))\n\texcept sr.UnknownValueError:                            # 語音無法辨識\n\t\tprint(\"Google Web Speech could not understand the audio\")\n\texcept sr.Request as e:                                 # google伺服器錯誤訊息\n\t\tprint(\"Could not request results form Google Web service\")\n```\n\n## Brain\n確認已安裝 Hugging Chat API。\n```bash\npip instal hugchat\n```\n\n接著將 Hugging Chat 導入到程式碼。\n```python\nfrom hugchat import hugchat\nfrom hugchat.login import Login\n```\n\n導入完後，確認已申請 Huggingface 的帳號，並將 email, passwd 分別輸入申請時的電子郵件帳號及 Huggingface 的密碼，這是用來在 python 程式中登入 Huggingface 帳號來使用 Hugging Chat的功能。\n```python\n# login\nemail = \"\"                                                  # 請輸入自己的email\npasswd = \"\"                                                 # 請輸入自己的密碼\nsign = Login(email, passwd)\ncookies = sign.login()\n```\n\n登入完後就可以啟動它了，這邊所使用 jarvis 變數可以改成任何名字。\n```python\n# activate\njarvis = hugchat.ChatBot(cookies=cookies.get_dict())\n```\n\n這邊建議將 login 和 activate 這兩個片段放在程式碼前端，完整程式碼我會放在最尾端。\n接著我們在語音辨識的程式碼後面將辨識好的文字送給 Hugging Chat 生成回答。\n```python\nresponse = jarvis.chat(message)\n```\n\n## 語音合成\n終於來到語音合成。這裡使用的語音合成模型會是 Google 的 gTTS，語音合成模型很多，也可以使用pytts 或是 OpenAI 的whisperAPI（這要付費，有一個開源模型也是whisper，是 OpenAI 訓練的，但他只有與語音轉文字而已，在 Gama 版我會介紹並使用）。除了 gTTS 我還會再使用 pydub 方便合成處理及播放音訊。\n安裝 [gTTS](<https://pypi.org/project/gTTS/>) 及 [pydub](<https://pypi.org/project/pydub/>)可以參閱說明文件。\n```bash\npip install gTTS pydub\n```\n\n接著只要將 gTTS 導入 python 程式就可以了。這裡我們要使用 pydub 裡的 AudioSegment 及 play 而已，以此只導入這兩個函式。\n```python\nfrom gtts import gTTS\n\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n```\n\n導入完工具後，接下來進行語音合成。設定合成的語言是英文，再把檔案存成 mp3 格式，但因為在之後用 pygame 編寫 GUI (使用者介面）時，只支援 16 位的 PCM wav 檔，因此要做轉檔的動作，有關 GUI 介面我會再找時間發一篇文章。 \n```python\ndef speak(text):\n\ttts = gTTS(text=text, lang='en') # 合成語言設定\n\ttts.save(\"response.mp3\")         # 音檔為 mp3 \n\t\n\t# 轉換為 16 位 PCM 格式的 WAV 文件\n\taudio = AudioSegment.from_mp3(\"response.mp3\")\n\taudio = audio.set_frame_rate(44100).set_channels(2).set_sample_width(2)\n\taudio.export(\"response.wav\", format='wav')\n```\n\n編寫完函式，只要將 Hugging Chat 產生的回答放入 speak 函式中就可以生成音檔了。最後在用play 播放音檔，我會習慣在語音播放完後輸出文字，確認講的內容，這行可以自行刪減。\n```python\nspeak(str(response))           # 強制轉型 string 格式怕 response 產生的文字格式不是字串\nplay(AudioSegment.from_wav(\"response.wav\"))\nprint(response)\n```\n\n# 完整的程式碼\n我在這裡加上了迴圈及停止方法（按下 Ctrl + C）可以終止程式。\n```python\nimport speech_recognition as sr\nfrom hugchat import hugchat\nfrom hugchat.login import Login\nfrom gtts import gTTS\nfrom pydub import AudioSegment\n\n# speaking\ndef speak(text):\n\ttts = gTTS(text=text, lang='en')\n\ttts.save(\"response.mp3\")\n\n\t# 轉換為 16 位 PCM 格式的 WAV 文件\n\taudio = AudioSegment.from_mp3(\"response.mp3\")\n\taudio = audio.set_frame_rate(44100).set_channels(2).set_sample_width(2)\n\taudio.export(\"response.wav\", format='wav')\n\n\n# initialize the recognizer\nr = sr.Recognizer()\n\n# log in\nemail = \"\"\npasswd = \"\"\nsign = Login(email, passwd)\ncookies = sign.login()\n\n# activate bot\njarvis = hugchat.ChatBot(cookies=cookies.get_dict())\n\n# generate response\nwhile(True):\n\ttry:\n\t\t# use the microphone as the source for input\n\t\twith sr.Microphone() as source:\n\t\t\tprint(\"Adjusting for ambient noise, please wait...\")\n\t\t\tr.adjust_for_ambient_noise(source)\n\t\t\tprint(\"Say something!\")\n\t\t\taudio = r.listen(source)\n\t\t\n\t\ttry:\n\t\t\tmessage = r.recognize_google(audio)\n\t\t\tprint(\"ME: \", r.recognize_google(audio))\n\t\texcept sr.UnknownValueError:\n\t\t\tprint(\"Google Web Speech could not understand the audio\")\n\t\texcept sr.Request as e:\n\t\t\tprint(\"Could not request results form Google Web service\")\n\t\t\n\t\t# generate the response\n\t\tresponse = jarvis.chat(message)\n\t\tspeak(str(response))\n\t\tprint(\"Jarvis: \", response)\n\texcept KeyboardInterrupt:\n\t\tprint(\"Exiting...\")\n\t\tbreak\n```\n\n# 後記\nGithub 上的檔案可能會晚點上，下一篇我會寫 Jarvis Beta 版，直接將預訓練好的模型載到電腦裡，越後面的版本呈現的效果越酷炫。","slug":"Jarvis-Alpha","published":1,"updated":"2024-08-15T08:31:31.736Z","comments":1,"photos":[],"_id":"clzv1q2h8000058y575gk96av","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>語音助理最廣為人知的應該是 Siri 以及 Alexa 了，而在電影 Iron man 中，有個 AI 叫做 J.A.R.V.I.S，專門幫助 Tony Stark 完成各種任務。雖然電影後面他發生了一些事，導致被另一個叫 Friday 的 AI 取代，有興趣的可以去觀看原作。其實我一直以來都很想有個語音AI，協助我處理各種事。兩年前我曾嘗試用 Open AI 的 ChatGPT API，由於 Open AI 訓練完 GPT3 模型之後，開始從開源逐漸走向收費，而 ChatGPT 的 API 免費版有用量限制，最後我專案還沒完成，卻已經用光所有的額度了。曾經有想過要自己訓練模型，但看著桌上的電腦，又默默地放下這個念頭，現階段訓練 AI 需要的硬體設備對我來說是遙不可及。但經過了兩年的時間，越來越多公司投入 AI 領域而且也「開源」了許多模型，也就是說不需要付費便能使用的 AI 模型。Jarvis 版本的命名採拉丁字母的順序，依照 Alpha, Beta, Gama…. 命名下去。這篇是 Jarvis Alpha 版本，我之後會陸續發部改良後的版本，雖然都叫 Jarvis 但其實使用的工具幾乎不一樣。Jarvis Alpha 版是以 Pyhon 進行編寫，我會將專案放在 <a href=\"https://github.com/Bakersite/Jarvis-Alpha.git\">Jarvis-Alpha</a> 。</p>\n<h1 id=\"Huggingface-的工具\"><a href=\"#Huggingface-的工具\" class=\"headerlink\" title=\"Huggingface 的工具\"></a>Huggingface 的工具</h1><h2 id=\"HuggingChat\"><a href=\"#HuggingChat\" class=\"headerlink\" title=\"HuggingChat\"></a>HuggingChat</h2><p>這邊要介紹 <a href=\"https://huggingface.co/\">Huggingface</a>，這是一個存放很多開源模型的平台，他除了有模型以外，也提供深度學習框架，有興趣的可以去探索一下，這邊會著墨在他底下一個叫 <a href=\"https://huggingface.co/chat/\">HuggingChat</a> 的生成式 AI 服務。由於在 Alpha 版中尚未用到使用 Huggingface 上的模型，因此有關模型的取用會留到 Beta 版在說明。</p>\n<p>HuggingChat 類似於大家熟悉的 ChatGPT ，比較不一樣在 HuggingChat 有許多種模型可以選擇。HuggingChat 也可以自定義 AI 的目的，像是以資深的軟體工程師來修正程式碼，可以在建立對話時便設定好，不需要每次都發送指定 AI 角色的 prompt。</p>\n<p>實作時會需要 Huggingface 的帳號，若要實作，可以先申請。</p>\n<p>P.S. 此文章發布時有一款模型 Llama3.1，由 Meta 訓練的開源模型，「據說」可以匹敵 Open AI 的 gpt-4o mini，各位可以玩玩看。</p>\n<h2 id=\"Hugging-Chat-API\"><a href=\"#Hugging-Chat-API\" class=\"headerlink\" title=\"Hugging Chat API\"></a>Hugging Chat API</h2><p><a href=\"https://github.com/Soulter/hugging-chat-api\">Hugging-Chat-API</a>它是一個大佬寫的，並不是 Huggingface 官方的 API，在 Alpha 版中我會利用它來連接 Hugging Chat 當作 Jarvis 的大腦，若有要實作的請先下載，建議參閱網站的說明文件，下面的安裝參考會比較簡潔。說明文件有詳細的指引，大家也可以試試用他的說明指引，自己做一個語音 AI。</p>\n<h1 id=\"實作\"><a href=\"#實作\" class=\"headerlink\" title=\"實作\"></a>實作</h1><h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><pre class=\"mermaid\">flowchart LR\nA(Speech to Text) \nB(Hugging Chat API) \nC[(Hugging Chat server)]\nD(Text to Speech)\nA --> B --> C --> D --> A</pre>\n\n<p>語音 AI 主要可以拆成三個步驟。</p>\n<ol>\n<li>語音辨識成文字 </li>\n<li>由生成式 AI 當作大腦進行理解 </li>\n<li>將生成的文字合成語音並播放</li>\n</ol>\n<h2 id=\"語音辨識\"><a href=\"#語音辨識\" class=\"headerlink\" title=\"語音辨識\"></a>語音辨識</h2><p>在這裡我們使用 Python 一個叫 <a href=\"https://pypi.org/project/SpeechRecognition/\">Speech Recognition</a> 的工具，利用這工具將語音轉換成文字。以下是簡易的安裝方法，完整說明可以參閱官方文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install SpeechRecognition</span><br></pre></td></tr></table></figure>\n\n<p>接下來只需要在 python 中導入模組即可。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> speech_recognition <span class=\"keyword\">as</span> sr</span><br></pre></td></tr></table></figure>\n\n<p>先初始化麥克風（建議放在程式碼開頭）接著我們將音訊輸入源調成麥克風，這裡會用 Google 的 Speech to Text 服務，將語音轉成文字，並存入 message 這個變數裡面。這裡會用 try, except 來處理無法辨識語音及連線到 Google 伺服器的錯誤（這邊我沒有將 Google 伺服器回彈的錯誤碼輸出，可以自己更改程式，或是直接在終端機查看）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># initialize the recognizer</span></span><br><span class=\"line\">r = sr.Recognizer()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># use the microphone as the source for input</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> sr.Microphone() <span class=\"keyword\">as</span> source:                             <span class=\"comment\"># 設定麥克風為音訊輸入源</span></span><br><span class=\"line\">\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Adjusting for ambient noise, please wait...&quot;</span>)</span><br><span class=\"line\">\tr.adjust_for_ambient_noise(source)                      <span class=\"comment\"># 處理背景雜音</span></span><br><span class=\"line\">\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Say something!&quot;</span>)</span><br><span class=\"line\">\taudio = r.listen(source)                                <span class=\"comment\"># 開始收音</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\tmessage = r.recognize_google(audio)                 <span class=\"comment\"># 將語音轉成文字</span></span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;ME: &quot;</span>, r.recognize_google(audio))</span><br><span class=\"line\">\t<span class=\"keyword\">except</span> sr.UnknownValueError:                            <span class=\"comment\"># 語音無法辨識</span></span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Google Web Speech could not understand the audio&quot;</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">except</span> sr.Request <span class=\"keyword\">as</span> e:                                 <span class=\"comment\"># google伺服器錯誤訊息</span></span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Could not request results form Google Web service&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Brain\"><a href=\"#Brain\" class=\"headerlink\" title=\"Brain\"></a>Brain</h2><p>確認已安裝 Hugging Chat API。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip instal hugchat</span><br></pre></td></tr></table></figure>\n\n<p>接著將 Hugging Chat 導入到程式碼。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> hugchat <span class=\"keyword\">import</span> hugchat</span><br><span class=\"line\"><span class=\"keyword\">from</span> hugchat.login <span class=\"keyword\">import</span> Login</span><br></pre></td></tr></table></figure>\n\n<p>導入完後，確認已申請 Huggingface 的帳號，並將 email, passwd 分別輸入申請時的電子郵件帳號及 Huggingface 的密碼，這是用來在 python 程式中登入 Huggingface 帳號來使用 Hugging Chat的功能。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># login</span></span><br><span class=\"line\">email = <span class=\"string\">&quot;&quot;</span>                                                  <span class=\"comment\"># 請輸入自己的email</span></span><br><span class=\"line\">passwd = <span class=\"string\">&quot;&quot;</span>                                                 <span class=\"comment\"># 請輸入自己的密碼</span></span><br><span class=\"line\">sign = Login(email, passwd)</span><br><span class=\"line\">cookies = sign.login()</span><br></pre></td></tr></table></figure>\n\n<p>登入完後就可以啟動它了，這邊所使用 jarvis 變數可以改成任何名字。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># activate</span></span><br><span class=\"line\">jarvis = hugchat.ChatBot(cookies=cookies.get_dict())</span><br></pre></td></tr></table></figure>\n\n<p>這邊建議將 login 和 activate 這兩個片段放在程式碼前端，完整程式碼我會放在最尾端。<br>接著我們在語音辨識的程式碼後面將辨識好的文字送給 Hugging Chat 生成回答。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">response = jarvis.chat(message)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"語音合成\"><a href=\"#語音合成\" class=\"headerlink\" title=\"語音合成\"></a>語音合成</h2><p>終於來到語音合成。這裡使用的語音合成模型會是 Google 的 gTTS，語音合成模型很多，也可以使用pytts 或是 OpenAI 的whisperAPI（這要付費，有一個開源模型也是whisper，是 OpenAI 訓練的，但他只有與語音轉文字而已，在 Gama 版我會介紹並使用）。除了 gTTS 我還會再使用 pydub 方便合成處理及播放音訊。<br>安裝 <a href=\"https://pypi.org/project/gTTS/\">gTTS</a> 及 <a href=\"https://pypi.org/project/pydub/\">pydub</a>可以參閱說明文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install gTTS pydub</span><br></pre></td></tr></table></figure>\n\n<p>接著只要將 gTTS 導入 python 程式就可以了。這裡我們要使用 pydub 裡的 AudioSegment 及 play 而已，以此只導入這兩個函式。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> gtts <span class=\"keyword\">import</span> gTTS</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> pydub <span class=\"keyword\">import</span> AudioSegment</span><br><span class=\"line\"><span class=\"keyword\">from</span> pydub.playback <span class=\"keyword\">import</span> play</span><br></pre></td></tr></table></figure>\n\n<p>導入完工具後，接下來進行語音合成。設定合成的語言是英文，再把檔案存成 mp3 格式，但因為在之後用 pygame 編寫 GUI (使用者介面）時，只支援 16 位的 PCM wav 檔，因此要做轉檔的動作，有關 GUI 介面我會再找時間發一篇文章。 </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">speak</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">\ttts = gTTS(text=text, lang=<span class=\"string\">&#x27;en&#x27;</span>) <span class=\"comment\"># 合成語言設定</span></span><br><span class=\"line\">\ttts.save(<span class=\"string\">&quot;response.mp3&quot;</span>)         <span class=\"comment\"># 音檔為 mp3 </span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 轉換為 16 位 PCM 格式的 WAV 文件</span></span><br><span class=\"line\">\taudio = AudioSegment.from_mp3(<span class=\"string\">&quot;response.mp3&quot;</span>)</span><br><span class=\"line\">\taudio = audio.set_frame_rate(<span class=\"number\">44100</span>).set_channels(<span class=\"number\">2</span>).set_sample_width(<span class=\"number\">2</span>)</span><br><span class=\"line\">\taudio.export(<span class=\"string\">&quot;response.wav&quot;</span>, <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;wav&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>編寫完函式，只要將 Hugging Chat 產生的回答放入 speak 函式中就可以生成音檔了。最後在用play 播放音檔，我會習慣在語音播放完後輸出文字，確認講的內容，這行可以自行刪減。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">speak(<span class=\"built_in\">str</span>(response))           <span class=\"comment\"># 強制轉型 string 格式怕 response 產生的文字格式不是字串</span></span><br><span class=\"line\">play(AudioSegment.from_wav(<span class=\"string\">&quot;response.wav&quot;</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"完整的程式碼\"><a href=\"#完整的程式碼\" class=\"headerlink\" title=\"完整的程式碼\"></a>完整的程式碼</h1><p>我在這裡加上了迴圈及停止方法（按下 Ctrl + C）可以終止程式。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> speech_recognition <span class=\"keyword\">as</span> sr</span><br><span class=\"line\"><span class=\"keyword\">from</span> hugchat <span class=\"keyword\">import</span> hugchat</span><br><span class=\"line\"><span class=\"keyword\">from</span> hugchat.login <span class=\"keyword\">import</span> Login</span><br><span class=\"line\"><span class=\"keyword\">from</span> gtts <span class=\"keyword\">import</span> gTTS</span><br><span class=\"line\"><span class=\"keyword\">from</span> pydub <span class=\"keyword\">import</span> AudioSegment</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># speaking</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">speak</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">\ttts = gTTS(text=text, lang=<span class=\"string\">&#x27;en&#x27;</span>)</span><br><span class=\"line\">\ttts.save(<span class=\"string\">&quot;response.mp3&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 轉換為 16 位 PCM 格式的 WAV 文件</span></span><br><span class=\"line\">\taudio = AudioSegment.from_mp3(<span class=\"string\">&quot;response.mp3&quot;</span>)</span><br><span class=\"line\">\taudio = audio.set_frame_rate(<span class=\"number\">44100</span>).set_channels(<span class=\"number\">2</span>).set_sample_width(<span class=\"number\">2</span>)</span><br><span class=\"line\">\taudio.export(<span class=\"string\">&quot;response.wav&quot;</span>, <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;wav&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize the recognizer</span></span><br><span class=\"line\">r = sr.Recognizer()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># log in</span></span><br><span class=\"line\">email = <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">passwd = <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">sign = Login(email, passwd)</span><br><span class=\"line\">cookies = sign.login()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># activate bot</span></span><br><span class=\"line\">jarvis = hugchat.ChatBot(cookies=cookies.get_dict())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate response</span></span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"literal\">True</span>):</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t<span class=\"comment\"># use the microphone as the source for input</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">with</span> sr.Microphone() <span class=\"keyword\">as</span> source:</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Adjusting for ambient noise, please wait...&quot;</span>)</span><br><span class=\"line\">\t\t\tr.adjust_for_ambient_noise(source)</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Say something!&quot;</span>)</span><br><span class=\"line\">\t\t\taudio = r.listen(source)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t\tmessage = r.recognize_google(audio)</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;ME: &quot;</span>, r.recognize_google(audio))</span><br><span class=\"line\">\t\t<span class=\"keyword\">except</span> sr.UnknownValueError:</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Google Web Speech could not understand the audio&quot;</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">except</span> sr.Request <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Could not request results form Google Web service&quot;</span>)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># generate the response</span></span><br><span class=\"line\">\t\tresponse = jarvis.chat(message)</span><br><span class=\"line\">\t\tspeak(<span class=\"built_in\">str</span>(response))</span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Jarvis: &quot;</span>, response)</span><br><span class=\"line\">\t<span class=\"keyword\">except</span> KeyboardInterrupt:</span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Exiting...&quot;</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"後記\"><a href=\"#後記\" class=\"headerlink\" title=\"後記\"></a>後記</h1><p>Github 上的檔案可能會晚點上，下一篇我會寫 Jarvis Beta 版，直接將預訓練好的模型載到電腦裡，越後面的版本呈現的效果越酷炫。</p>\n","excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>語音助理最廣為人知的應該是 Siri 以及 Alexa 了，而在電影 Iron man 中，有個 AI 叫做 J.A.R.V.I.S，專門幫助 Tony Stark 完成各種任務。雖然電影後面他發生了一些事，導致被另一個叫 Friday 的 AI 取代，有興趣的可以去觀看原作。其實我一直以來都很想有個語音AI，協助我處理各種事。兩年前我曾嘗試用 Open AI 的 ChatGPT API，由於 Open AI 訓練完 GPT3 模型之後，開始從開源逐漸走向收費，而 ChatGPT 的 API 免費版有用量限制，最後我專案還沒完成，卻已經用光所有的額度了。曾經有想過要自己訓練模型，但看著桌上的電腦，又默默地放下這個念頭，現階段訓練 AI 需要的硬體設備對我來說是遙不可及。但經過了兩年的時間，越來越多公司投入 AI 領域而且也「開源」了許多模型，也就是說不需要付費便能使用的 AI 模型。Jarvis 版本的命名採拉丁字母的順序，依照 Alpha, Beta, Gama…. 命名下去。這篇是 Jarvis Alpha 版本，我之後會陸續發部改良後的版本，雖然都叫 Jarvis 但其實使用的工具幾乎不一樣。Jarvis Alpha 版是以 Pyhon 進行編寫，我會將專案放在 <a href=\"https://github.com/Bakersite/Jarvis-Alpha.git\">Jarvis-Alpha</a> 。</p>\n<h1 id=\"Huggingface-的工具\"><a href=\"#Huggingface-的工具\" class=\"headerlink\" title=\"Huggingface 的工具\"></a>Huggingface 的工具</h1><h2 id=\"HuggingChat\"><a href=\"#HuggingChat\" class=\"headerlink\" title=\"HuggingChat\"></a>HuggingChat</h2><p>這邊要介紹 <a href=\"https://huggingface.co/\">Huggingface</a>，這是一個存放很多開源模型的平台，他除了有模型以外，也提供深度學習框架，有興趣的可以去探索一下，這邊會著墨在他底下一個叫 <a href=\"https://huggingface.co/chat/\">HuggingChat</a> 的生成式 AI 服務。由於在 Alpha 版中尚未用到使用 Huggingface 上的模型，因此有關模型的取用會留到 Beta 版在說明。</p>\n<p>HuggingChat 類似於大家熟悉的 ChatGPT ，比較不一樣在 HuggingChat 有許多種模型可以選擇。HuggingChat 也可以自定義 AI 的目的，像是以資深的軟體工程師來修正程式碼，可以在建立對話時便設定好，不需要每次都發送指定 AI 角色的 prompt。</p>\n<p>實作時會需要 Huggingface 的帳號，若要實作，可以先申請。</p>\n<p>P.S. 此文章發布時有一款模型 Llama3.1，由 Meta 訓練的開源模型，「據說」可以匹敵 Open AI 的 gpt-4o mini，各位可以玩玩看。</p>\n<h2 id=\"Hugging-Chat-API\"><a href=\"#Hugging-Chat-API\" class=\"headerlink\" title=\"Hugging Chat API\"></a>Hugging Chat API</h2><p><a href=\"https://github.com/Soulter/hugging-chat-api\">Hugging-Chat-API</a>它是一個大佬寫的，並不是 Huggingface 官方的 API，在 Alpha 版中我會利用它來連接 Hugging Chat 當作 Jarvis 的大腦，若有要實作的請先下載，建議參閱網站的說明文件，下面的安裝參考會比較簡潔。說明文件有詳細的指引，大家也可以試試用他的說明指引，自己做一個語音 AI。</p>\n<h1 id=\"實作\"><a href=\"#實作\" class=\"headerlink\" title=\"實作\"></a>實作</h1><h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><pre class=\"mermaid\">flowchart LR\nA(Speech to Text) \nB(Hugging Chat API) \nC[(Hugging Chat server)]\nD(Text to Speech)\nA --> B --> C --> D --> A</pre>\n\n<p>語音 AI 主要可以拆成三個步驟。</p>\n<ol>\n<li>語音辨識成文字 </li>\n<li>由生成式 AI 當作大腦進行理解 </li>\n<li>將生成的文字合成語音並播放</li>\n</ol>\n<h2 id=\"語音辨識\"><a href=\"#語音辨識\" class=\"headerlink\" title=\"語音辨識\"></a>語音辨識</h2><p>在這裡我們使用 Python 一個叫 <a href=\"https://pypi.org/project/SpeechRecognition/\">Speech Recognition</a> 的工具，利用這工具將語音轉換成文字。以下是簡易的安裝方法，完整說明可以參閱官方文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install SpeechRecognition</span><br></pre></td></tr></table></figure>\n\n<p>接下來只需要在 python 中導入模組即可。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> speech_recognition <span class=\"keyword\">as</span> sr</span><br></pre></td></tr></table></figure>\n\n<p>先初始化麥克風（建議放在程式碼開頭）接著我們將音訊輸入源調成麥克風，這裡會用 Google 的 Speech to Text 服務，將語音轉成文字，並存入 message 這個變數裡面。這裡會用 try, except 來處理無法辨識語音及連線到 Google 伺服器的錯誤（這邊我沒有將 Google 伺服器回彈的錯誤碼輸出，可以自己更改程式，或是直接在終端機查看）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># initialize the recognizer</span></span><br><span class=\"line\">r = sr.Recognizer()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># use the microphone as the source for input</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> sr.Microphone() <span class=\"keyword\">as</span> source:                             <span class=\"comment\"># 設定麥克風為音訊輸入源</span></span><br><span class=\"line\">\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Adjusting for ambient noise, please wait...&quot;</span>)</span><br><span class=\"line\">\tr.adjust_for_ambient_noise(source)                      <span class=\"comment\"># 處理背景雜音</span></span><br><span class=\"line\">\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Say something!&quot;</span>)</span><br><span class=\"line\">\taudio = r.listen(source)                                <span class=\"comment\"># 開始收音</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\tmessage = r.recognize_google(audio)                 <span class=\"comment\"># 將語音轉成文字</span></span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;ME: &quot;</span>, r.recognize_google(audio))</span><br><span class=\"line\">\t<span class=\"keyword\">except</span> sr.UnknownValueError:                            <span class=\"comment\"># 語音無法辨識</span></span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Google Web Speech could not understand the audio&quot;</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">except</span> sr.Request <span class=\"keyword\">as</span> e:                                 <span class=\"comment\"># google伺服器錯誤訊息</span></span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Could not request results form Google Web service&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Brain\"><a href=\"#Brain\" class=\"headerlink\" title=\"Brain\"></a>Brain</h2><p>確認已安裝 Hugging Chat API。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip instal hugchat</span><br></pre></td></tr></table></figure>\n\n<p>接著將 Hugging Chat 導入到程式碼。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> hugchat <span class=\"keyword\">import</span> hugchat</span><br><span class=\"line\"><span class=\"keyword\">from</span> hugchat.login <span class=\"keyword\">import</span> Login</span><br></pre></td></tr></table></figure>\n\n<p>導入完後，確認已申請 Huggingface 的帳號，並將 email, passwd 分別輸入申請時的電子郵件帳號及 Huggingface 的密碼，這是用來在 python 程式中登入 Huggingface 帳號來使用 Hugging Chat的功能。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># login</span></span><br><span class=\"line\">email = <span class=\"string\">&quot;&quot;</span>                                                  <span class=\"comment\"># 請輸入自己的email</span></span><br><span class=\"line\">passwd = <span class=\"string\">&quot;&quot;</span>                                                 <span class=\"comment\"># 請輸入自己的密碼</span></span><br><span class=\"line\">sign = Login(email, passwd)</span><br><span class=\"line\">cookies = sign.login()</span><br></pre></td></tr></table></figure>\n\n<p>登入完後就可以啟動它了，這邊所使用 jarvis 變數可以改成任何名字。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># activate</span></span><br><span class=\"line\">jarvis = hugchat.ChatBot(cookies=cookies.get_dict())</span><br></pre></td></tr></table></figure>\n\n<p>這邊建議將 login 和 activate 這兩個片段放在程式碼前端，完整程式碼我會放在最尾端。<br>接著我們在語音辨識的程式碼後面將辨識好的文字送給 Hugging Chat 生成回答。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">response = jarvis.chat(message)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"語音合成\"><a href=\"#語音合成\" class=\"headerlink\" title=\"語音合成\"></a>語音合成</h2><p>終於來到語音合成。這裡使用的語音合成模型會是 Google 的 gTTS，語音合成模型很多，也可以使用pytts 或是 OpenAI 的whisperAPI（這要付費，有一個開源模型也是whisper，是 OpenAI 訓練的，但他只有與語音轉文字而已，在 Gama 版我會介紹並使用）。除了 gTTS 我還會再使用 pydub 方便合成處理及播放音訊。<br>安裝 <a href=\"https://pypi.org/project/gTTS/\">gTTS</a> 及 <a href=\"https://pypi.org/project/pydub/\">pydub</a>可以參閱說明文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install gTTS pydub</span><br></pre></td></tr></table></figure>\n\n<p>接著只要將 gTTS 導入 python 程式就可以了。這裡我們要使用 pydub 裡的 AudioSegment 及 play 而已，以此只導入這兩個函式。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> gtts <span class=\"keyword\">import</span> gTTS</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> pydub <span class=\"keyword\">import</span> AudioSegment</span><br><span class=\"line\"><span class=\"keyword\">from</span> pydub.playback <span class=\"keyword\">import</span> play</span><br></pre></td></tr></table></figure>\n\n<p>導入完工具後，接下來進行語音合成。設定合成的語言是英文，再把檔案存成 mp3 格式，但因為在之後用 pygame 編寫 GUI (使用者介面）時，只支援 16 位的 PCM wav 檔，因此要做轉檔的動作，有關 GUI 介面我會再找時間發一篇文章。 </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">speak</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">\ttts = gTTS(text=text, lang=<span class=\"string\">&#x27;en&#x27;</span>) <span class=\"comment\"># 合成語言設定</span></span><br><span class=\"line\">\ttts.save(<span class=\"string\">&quot;response.mp3&quot;</span>)         <span class=\"comment\"># 音檔為 mp3 </span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 轉換為 16 位 PCM 格式的 WAV 文件</span></span><br><span class=\"line\">\taudio = AudioSegment.from_mp3(<span class=\"string\">&quot;response.mp3&quot;</span>)</span><br><span class=\"line\">\taudio = audio.set_frame_rate(<span class=\"number\">44100</span>).set_channels(<span class=\"number\">2</span>).set_sample_width(<span class=\"number\">2</span>)</span><br><span class=\"line\">\taudio.export(<span class=\"string\">&quot;response.wav&quot;</span>, <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;wav&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>編寫完函式，只要將 Hugging Chat 產生的回答放入 speak 函式中就可以生成音檔了。最後在用play 播放音檔，我會習慣在語音播放完後輸出文字，確認講的內容，這行可以自行刪減。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">speak(<span class=\"built_in\">str</span>(response))           <span class=\"comment\"># 強制轉型 string 格式怕 response 產生的文字格式不是字串</span></span><br><span class=\"line\">play(AudioSegment.from_wav(<span class=\"string\">&quot;response.wav&quot;</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response)</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"完整的程式碼\"><a href=\"#完整的程式碼\" class=\"headerlink\" title=\"完整的程式碼\"></a>完整的程式碼</h1><p>我在這裡加上了迴圈及停止方法（按下 Ctrl + C）可以終止程式。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> speech_recognition <span class=\"keyword\">as</span> sr</span><br><span class=\"line\"><span class=\"keyword\">from</span> hugchat <span class=\"keyword\">import</span> hugchat</span><br><span class=\"line\"><span class=\"keyword\">from</span> hugchat.login <span class=\"keyword\">import</span> Login</span><br><span class=\"line\"><span class=\"keyword\">from</span> gtts <span class=\"keyword\">import</span> gTTS</span><br><span class=\"line\"><span class=\"keyword\">from</span> pydub <span class=\"keyword\">import</span> AudioSegment</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># speaking</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">speak</span>(<span class=\"params\">text</span>):</span><br><span class=\"line\">\ttts = gTTS(text=text, lang=<span class=\"string\">&#x27;en&#x27;</span>)</span><br><span class=\"line\">\ttts.save(<span class=\"string\">&quot;response.mp3&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 轉換為 16 位 PCM 格式的 WAV 文件</span></span><br><span class=\"line\">\taudio = AudioSegment.from_mp3(<span class=\"string\">&quot;response.mp3&quot;</span>)</span><br><span class=\"line\">\taudio = audio.set_frame_rate(<span class=\"number\">44100</span>).set_channels(<span class=\"number\">2</span>).set_sample_width(<span class=\"number\">2</span>)</span><br><span class=\"line\">\taudio.export(<span class=\"string\">&quot;response.wav&quot;</span>, <span class=\"built_in\">format</span>=<span class=\"string\">&#x27;wav&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize the recognizer</span></span><br><span class=\"line\">r = sr.Recognizer()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># log in</span></span><br><span class=\"line\">email = <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">passwd = <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">sign = Login(email, passwd)</span><br><span class=\"line\">cookies = sign.login()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># activate bot</span></span><br><span class=\"line\">jarvis = hugchat.ChatBot(cookies=cookies.get_dict())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># generate response</span></span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"literal\">True</span>):</span><br><span class=\"line\">\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t<span class=\"comment\"># use the microphone as the source for input</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">with</span> sr.Microphone() <span class=\"keyword\">as</span> source:</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Adjusting for ambient noise, please wait...&quot;</span>)</span><br><span class=\"line\">\t\t\tr.adjust_for_ambient_noise(source)</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Say something!&quot;</span>)</span><br><span class=\"line\">\t\t\taudio = r.listen(source)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">try</span>:</span><br><span class=\"line\">\t\t\tmessage = r.recognize_google(audio)</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;ME: &quot;</span>, r.recognize_google(audio))</span><br><span class=\"line\">\t\t<span class=\"keyword\">except</span> sr.UnknownValueError:</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Google Web Speech could not understand the audio&quot;</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">except</span> sr.Request <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Could not request results form Google Web service&quot;</span>)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># generate the response</span></span><br><span class=\"line\">\t\tresponse = jarvis.chat(message)</span><br><span class=\"line\">\t\tspeak(<span class=\"built_in\">str</span>(response))</span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Jarvis: &quot;</span>, response)</span><br><span class=\"line\">\t<span class=\"keyword\">except</span> KeyboardInterrupt:</span><br><span class=\"line\">\t\t<span class=\"built_in\">print</span>(<span class=\"string\">&quot;Exiting...&quot;</span>)</span><br><span class=\"line\">\t\t<span class=\"keyword\">break</span></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"後記\"><a href=\"#後記\" class=\"headerlink\" title=\"後記\"></a>後記</h1><p>Github 上的檔案可能會晚點上，下一篇我會寫 Jarvis Beta 版，直接將預訓練好的模型載到電腦裡，越後面的版本呈現的效果越酷炫。</p>\n"},{"layout":"posts","title":"Welcome to Bakersite","date":"2024-08-14T09:44:42.000Z","_content":"這裡會分享一些科技相關的文章，可能有些人會因為不會寫程式而放棄去探索一些領域的內容，然而生成式AI其實可以解決程式能力的問題，希望這裡的內容，能幫助到對科技有興趣的人。文章中的程式碼大多數是由AI進行編寫，這裡的程式碼不是重點，最主要的目的是介紹一些好用得工具或是App。我會盡量將文章寫的淺顯易懂，讓更多人能體驗。","source":"_posts/Welcome-to-Bakersite.md","raw":"---\nlayout: posts\ntitle: Welcome to Bakersite\ndate: 2024-08-14 17:44:42\ntags:\n---\n這裡會分享一些科技相關的文章，可能有些人會因為不會寫程式而放棄去探索一些領域的內容，然而生成式AI其實可以解決程式能力的問題，希望這裡的內容，能幫助到對科技有興趣的人。文章中的程式碼大多數是由AI進行編寫，這裡的程式碼不是重點，最主要的目的是介紹一些好用得工具或是App。我會盡量將文章寫的淺顯易懂，讓更多人能體驗。","slug":"Welcome-to-Bakersite","published":1,"updated":"2024-08-14T09:44:49.875Z","comments":1,"photos":[],"_id":"clzv1q2ha000158y53l4wdiqh","content":"<p>這裡會分享一些科技相關的文章，可能有些人會因為不會寫程式而放棄去探索一些領域的內容，然而生成式AI其實可以解決程式能力的問題，希望這裡的內容，能幫助到對科技有興趣的人。文章中的程式碼大多數是由AI進行編寫，這裡的程式碼不是重點，最主要的目的是介紹一些好用得工具或是App。我會盡量將文章寫的淺顯易懂，讓更多人能體驗。</p>\n","excerpt":"","more":"<p>這裡會分享一些科技相關的文章，可能有些人會因為不會寫程式而放棄去探索一些領域的內容，然而生成式AI其實可以解決程式能力的問題，希望這裡的內容，能幫助到對科技有興趣的人。文章中的程式碼大多數是由AI進行編寫，這裡的程式碼不是重點，最主要的目的是介紹一些好用得工具或是App。我會盡量將文章寫的淺顯易懂，讓更多人能體驗。</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"clzv1q2h8000058y575gk96av","tag_id":"clzv1q2hb000258y5dgg4d1eh","_id":"clzv1q2hc000658y51iq8drqh"},{"post_id":"clzv1q2h8000058y575gk96av","tag_id":"clzv1q2hc000358y534oc79cd","_id":"clzv1q2hc000758y57bf62hai"},{"post_id":"clzv1q2h8000058y575gk96av","tag_id":"clzv1q2hc000458y50l9je159","_id":"clzv1q2hc000858y57dg0cmrl"},{"post_id":"clzv1q2h8000058y575gk96av","tag_id":"clzv1q2hc000558y54xth4t4z","_id":"clzv1q2hc000958y5bwi4fanh"}],"Tag":[{"name":"Jarvis","_id":"clzv1q2hb000258y5dgg4d1eh"},{"name":"Huggingface","_id":"clzv1q2hc000358y534oc79cd"},{"name":"gTTS","_id":"clzv1q2hc000458y50l9je159"},{"name":"AI","_id":"clzv1q2hc000558y54xth4t4z"}]}}